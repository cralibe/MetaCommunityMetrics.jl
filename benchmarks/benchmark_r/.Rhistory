if(symmetrize == TRUE)
{
Add <- which(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]])) == max(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]]))))
if(Add == 1)
{
sampled_lines <- sample(1:length(splitx[[group.combinations[1,i]]][,1]),
length(splitx[[group.combinations[2,i]]][,1]))
splitx[[group.combinations[1,i]]] <- splitx[[group.combinations[1,i]]][sampled_lines,]
}
if(Add == 2)
{
sampled_lines <- sample(1:length(splitx[[group.combinations[2,i]]][,1]),
length(splitx[[group.combinations[1,i]]][,1]))
splitx[[group.combinations[2,i]]] <- splitx[[group.combinations[2,i]]][sampled_lines,]
}
}
Add <- which(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]])) == max(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]]))))
Add
sampled_lines <- sample(1:length(splitx[[group.combinations[1,i]]][,1]),
length(splitx[[group.combinations[2,i]]][,1]))
sampled_lines <- sample(1:length(splitx[[group.combinations[1,i]]][,1]),
length(splitx[[group.combinations[2,i]]][,1]))
splitx[[group.combinations[1,i]]][,1]
group.combinations[1,i]]][,1
length(splitx[[group.combinations[1,i]]][,1])
splitx[[group.combinations[1,i]]][,1]
group.combinations[1,i]
splitx[[group.combinations[1,i]]]
splitx[[group.combinations[1,i]]][,1]
splitx <- split(x,grouping)
sampled_lines <- sample(1:length(splitx[[group.combinations[1,i]]][,1]),
length(splitx[[group.combinations[2,i]]][,1]))
splitx
splitx <- split(x,grouping)
splitx
x=Matrix
load("Data_Matrix_Tutorial.RData") #Data already loaded with DNCImper package. Can be call like that: DNCImper::Matrix
library(vegan)
library(plyr)
library(ggplot2)
library(DNCImper)
load("Data_Matrix_Tutorial.RData") #Data already loaded with DNCImper package. Can be call like that: DNCImper::Matrix
DNCImper::Matrix
DNCImper::Group
grouping=Group
x=Matrix
group.combinations <- combn(unique(sort(grouping)),2)
ddelta <- NULL
for(i in 1:NCOL(group.combinations)) {
splitx <- split(x,grouping)
#Ici symmetrize:
if(symmetrize == TRUE)
{
Add <- which(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]])) == max(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]]))))
if(Add == 1)
{
sampled_lines <- sample(1:length(splitx[[group.combinations[1,i]]][,1]),
length(splitx[[group.combinations[2,i]]][,1]))
splitx[[group.combinations[1,i]]] <- splitx[[group.combinations[1,i]]][sampled_lines,]
}
if(Add == 2)
{
sampled_lines <- sample(1:length(splitx[[group.combinations[2,i]]][,1]),
length(splitx[[group.combinations[1,i]]][,1]))
splitx[[group.combinations[2,i]]] <- splitx[[group.combinations[2,i]]][sampled_lines,]
}
}
paired.x <- rbind(splitx[[group.combinations[1,i]]],
splitx[[group.combinations[2,i]]])
# remove empty species
ifzero <- which(apply(paired.x, 2, sum) == 0)
if(length(ifzero > 0)){
paired.x <- paired.x[,-which(colSums(paired.x)==0)]}
if(length(which(rowSums(paired.x) == 0)) != 0){stop("ERROR : A row/sample is empty")}
group.pair <- c(rep(group.combinations[1,i], NROW(splitx[[group.combinations[1,i]]])),
rep(group.combinations[2,i], NROW(splitx[[group.combinations[2,i]]])))
ddelta <- rbind(ddelta, DNCImper:::DNCI.ses(x=paired.x,grouping=group.pair,id=id, Nperm = Nperm, count = count, plotSIMPER = plotSIMPER, dataTYPE = dataTYPE)) #here is the part that calculates the index based on PERSIMPER
}
splitx <- split(x,grouping)
splitx
Add <- which(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]])) == max(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]]))))
splitx[[group.combinations[1,i]]][,1]
i
group.combinations[1,i]
group.combinations
(splitx[[group.combinations[1,i]]]
)
splitx[[group.combinations[1,i]]]
splitx[[1]]
splitx
splitx[[group.combinations[1,i]]][,1]
grouping=groups
grouping
x=comm_df_for_DNCI
x
group.combinations <- combn(unique(sort(grouping)),2)
group.combinations
splitx <- split(x,grouping)
splitx
Matrix
Group
?split()
x
grouping
split(x,grouping)
comm_df_for_DNCI<-read.csv("~/.julia/dev/MetaCommunityMetrics/benchmarks/benchmark_r/data/DNCI_comm.csv")
comm_df_for_DNCI
split(x,grouping)
grouping
x
grouping
split(x,grouping)
x=Matrix
grouping=Group
x
grouping
split(x,grouping)
x=comm_df_for_DNCI
x
x=as.matrix(comm_df_for_DNCI)
x
grouping
grouping=groups
grouping
split(x,grouping)
str(Matrix)
str(comm_df_for_DNCI)
split(comm_df_for_DNCI, groups)
x=comm_df_for_DNCI
str(X)
str(x)
grouping=groups
split(x,grouping)
group.combinations <- combn(unique(sort(grouping)),2)
group.combinations
ddelta <- NULL
for(i in 1:NCOL(group.combinations)) {
splitx <- split(x,grouping)
#Ici symmetrize:
if(symmetrize == TRUE)
{
Add <- which(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]])) == max(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]]))))
if(Add == 1)
{
sampled_lines <- sample(1:length(splitx[[group.combinations[1,i]]][,1]),
length(splitx[[group.combinations[2,i]]][,1]))
splitx[[group.combinations[1,i]]] <- splitx[[group.combinations[1,i]]][sampled_lines,]
}
if(Add == 2)
{
sampled_lines <- sample(1:length(splitx[[group.combinations[2,i]]][,1]),
length(splitx[[group.combinations[1,i]]][,1]))
splitx[[group.combinations[2,i]]] <- splitx[[group.combinations[2,i]]][sampled_lines,]
}
}
paired.x <- rbind(splitx[[group.combinations[1,i]]],
splitx[[group.combinations[2,i]]])
# remove empty species
ifzero <- which(apply(paired.x, 2, sum) == 0)
if(length(ifzero > 0)){
paired.x <- paired.x[,-which(colSums(paired.x)==0)]}
if(length(which(rowSums(paired.x) == 0)) != 0){stop("ERROR : A row/sample is empty")}
group.pair <- c(rep(group.combinations[1,i], NROW(splitx[[group.combinations[1,i]]])),
rep(group.combinations[2,i], NROW(splitx[[group.combinations[2,i]]])))
ddelta <- rbind(ddelta, DNCImper:::DNCI.ses(x=paired.x,grouping=group.pair,id=id, Nperm = Nperm, count = count, plotSIMPER = plotSIMPER, dataTYPE = dataTYPE)) #here is the part that calculates the index based on PERSIMPER
}
splitx <- split(x,grouping)
splitx
Add <- which(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]])) == max(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]]))))
Add
sampled_lines <- sample(1:length(splitx[[group.combinations[1,i]]][,1]),
length(splitx[[group.combinations[2,i]]][,1]))
splitx[[group.combinations[1,i]]] <- splitx[[group.combinations[1,i]]][sampled_lines,]
paired.x <- rbind(splitx[[group.combinations[1,i]]],
splitx[[group.combinations[2,i]]])
length(which(rowSums(paired.x)
)
)
length(which(rowSums(paired.x) == 0))
if(symmetrize == TRUE)
{
Add <- which(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]])) == max(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]]))))
if(Add == 1)
{
sampled_lines <- sample(1:length(splitx[[group.combinations[1,i]]][,1]),
length(splitx[[group.combinations[2,i]]][,1]))
splitx[[group.combinations[1,i]]] <- splitx[[group.combinations[1,i]]][sampled_lines,]
}
if(Add == 2)
{
sampled_lines <- sample(1:length(splitx[[group.combinations[2,i]]][,1]),
length(splitx[[group.combinations[1,i]]][,1]))
splitx[[group.combinations[2,i]]] <- splitx[[group.combinations[2,i]]][sampled_lines,]
}
}
splitx <- split(x,grouping)
#Ici symmetrize:
if(symmetrize == TRUE)
{
Add <- which(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]])) == max(c(NROW(splitx[[group.combinations[1,i]]]),
NROW(splitx[[group.combinations[2,i]]]))))
if(Add == 1)
{
sampled_lines <- sample(1:length(splitx[[group.combinations[1,i]]][,1]),
length(splitx[[group.combinations[2,i]]][,1]))
splitx[[group.combinations[1,i]]] <- splitx[[group.combinations[1,i]]][sampled_lines,]
}
if(Add == 2)
{
sampled_lines <- sample(1:length(splitx[[group.combinations[2,i]]][,1]),
length(splitx[[group.combinations[1,i]]][,1]))
splitx[[group.combinations[2,i]]] <- splitx[[group.combinations[2,i]]][sampled_lines,]
}
}
i
paired.x <- rbind(splitx[[group.combinations[1,i]]],
splitx[[group.combinations[2,i]]])
ifzero <- which(apply(paired.x, 2, sum) == 0)
if(length(ifzero > 0)){
paired.x <- paired.x[,-which(colSums(paired.x)==0)]}
if(length(which(rowSums(paired.x) == 0)) != 0){stop("ERROR : A row/sample is empty")}
length(which(rowSums(paired.x) == 0))
rowSums(paired.x)
paired.x
rowSums(paired.x)
which(rowSums(paired.x) == 0)
rowSums(paired.x) == 0
which(rowSums(paired.x) == 0)
length(which(rowSums(paired.x) == 0))
apply(paired.x, 2, sum)
paired.x
which(apply(paired.x, 2, sum) == 0)
comm_df_for_DNCI
ts_metacom <- apply(metacomm_tsdata,2,sum)
metacomm_tsdata <- array(0, dim = c(length(species_vals), length(date_vals), length(plot_vals)))
species_vals <- unique(df$Species)
date_vals <- unique(df$Sampling_date_order)
plot_vals <- unique(df$plot)
# Create the array with dimensions based on unique Species, Sampling_date_order, and plot
metacomm_tsdata <- array(0, dim = c(length(species_vals), length(date_vals), length(plot_vals)))
# Step 3: Populate the array with values from the data frame
for(i in 1:nrow(df)){
# Map Species, Sampling_date_order, and plot to their corresponding indices
species_index <- which(species_vals == df$Species[i])
date_index <- which(date_vals == df$Sampling_date_order[i])
plot_index <- which(plot_vals == df$plot[i])
# Assign the value from the data frame (Abundance) to the array
metacomm_tsdata[species_index, date_index, plot_index] <- df$Abundance[i]
}
metacomm_tsdata
metacomm_tsdata[,,24]
ts_metacom <- apply(metacomm_tsdata,2,sum)
ts_metacom <- apply(metacomm_tsdata,2,sum)
ts_patch <- apply(metacomm_tsdata,c(2,3),sum)
ts_species <- apply(metacomm_tsdata,c(1,2),sum)
sd_metacom <- sd(ts_metacom)
sd_patch_k <- apply(ts_patch,2,sd)
sd_species_i <- apply(ts_species,1,sd)
sd_species_patch_ik <- apply(metacomm_tsdata,c(1,3),sd)
mean_metacom <- mean(ts_metacom)
CV_S_L <- sum(sd_species_patch_ik)/mean_metacom
CV_C_L <- sum(sd_patch_k)/mean_metacom
CV_S_R <- sum(sd_species_i)/mean_metacom
CV_C_R <- sd_metacom/mean_metacom
ts_metacom
metacomm_tsdata[,1,]
metacomm_tsdata[,1,]
#sp=5,plot=14
df%>%filter(Sampling_date_order==1)%>%
filter(plot==14)
library(dyplr)
library(dplyr)
df%>%filter(Sampling_date_order==1)%>%
filter(plot==14)
#Read in the sample data
df <- read.csv("~/.julia/dev/MetaCommunityMetrics/data/metacomm_rodent_df.csv")%>%
mutate(Species=as.character(Species))
df%>%filter(Sampling_date_order==1)%>%
filter(plot==14)
#Read in the sample data
df <- read.csv("~/.julia/dev/MetaCommunityMetrics/data/metacomm_rodent_df.csv", na.strings = c("", "NA"), stringsAsFactors = FALSE)
df%>%filter(Sampling_date_order==1)%>%
filter(plot==14)
#Read in the sample data
df <- read.csv("~/.julia/dev/MetaCommunityMetrics/data/metacomm_rodent_df.csv", na.strings = c("", "NA"), stringsAsFactors = TRUE)
df%>%filter(Sampling_date_order==1)%>%
filter(plot==14)
#Read in the sample data
df <- read.csv("~/.julia/dev/MetaCommunityMetrics/data/metacomm_rodent_df.csv", na.strings = c("NA", "NA_sp"), stringsAsFactors = TRUE)
df%>%filter(Sampling_date_order==1)%>%
filter(plot==14)
df <- read.csv("~/.julia/dev/MetaCommunityMetrics/data/metacomm_rodent_df.csv")
df$species[is.na(df$species)] <- "NA"
df$species[is.na(df$Species)] <- "NA"
#Read in the sample data
df <- read.csv("~/.julia/dev/MetaCommunityMetrics/data/metacomm_rodent_df.csv")
df$species[is.na(df$Species)] <- "NA"
df%>%filter(Sampling_date_order==1)%>%
filter(plot==14)
df <- read.csv("~/.julia/dev/MetaCommunityMetrics/data/metacomm_rodent_df.csv")
df$species[is.na(df$Species)] <- "NA_sp"
df%>%filter(Sampling_date_order==1)%>%
filter(plot==14)
is.na(df$Species)
df$species[is.na(df$Species)] <- "NA_sp"
df%>%filter(Sampling_date_order==1)%>%
filter(plot==14)
#Read in the sample data
df <- read.csv("~/.julia/dev/MetaCommunityMetrics/data/metacomm_rodent_df.csv", , na.strings = c(""), stringsAsFactors = FALSE)
df%>%filter(Sampling_date_order==1)%>%
filter(plot==14)
species_vals <- unique(df$Species)
date_vals <- unique(df$Sampling_date_order)
plot_vals <- unique(df$plot)
# Create the array with dimensions based on unique Species, Sampling_date_order, and plot
metacomm_tsdata <- array(0, dim = c(length(species_vals), length(date_vals), length(plot_vals)))
for(i in 1:nrow(df)){
# Map Species, Sampling_date_order, and plot to their corresponding indices
species_index <- which(species_vals == df$Species[i])
date_index <- which(date_vals == df$Sampling_date_order[i])
plot_index <- which(plot_vals == df$plot[i])
# Assign the value from the data frame (Abundance) to the array
metacomm_tsdata[species_index, date_index, plot_index] <- df$Abundance[i]
}
test=var.partition(metacomm_tsdata)
var.partition <- function(metacomm_tsdata){
## The function "var.partition" performs the partitioning of variability
## across hierarchical levesl within a metacommunity.
## The input array "metacomm_tsdata" is an N*T*M array. The first dimension represents N species,
## the second represents time-series observations of length T, and the third represents M local communities.
## The output includes four variability and four synchrony metrics as defined in the main text.
## Note that, to be able to handle large metacommunities, this code has avoided calculating all covariance.
ts_metacom <- apply(metacomm_tsdata,2,sum)
ts_patch <- apply(metacomm_tsdata,c(2,3),sum)
ts_species <- apply(metacomm_tsdata,c(1,2),sum)
sd_metacom <- sd(ts_metacom)
sd_patch_k <- apply(ts_patch,2,sd)
sd_species_i <- apply(ts_species,1,sd)
sd_species_patch_ik <- apply(metacomm_tsdata,c(1,3),sd)
mean_metacom <- mean(ts_metacom)
CV_S_L <- sum(sd_species_patch_ik)/mean_metacom
CV_C_L <- sum(sd_patch_k)/mean_metacom
CV_S_R <- sum(sd_species_i)/mean_metacom
CV_C_R <- sd_metacom/mean_metacom
summary <- c(CV_S_L=CV_S_L, CV_C_L=CV_C_L, CV_S_R=CV_S_R, CV_C_R=CV_C_R)
return(summary)
}
test=var.partition(metacomm_tsdata)
test
#Read in the sample data
df <- read.csv("~/.julia/dev/MetaCommunityMetrics/data/metacomm_rodent_df.csv",na.strings = c(""), stringsAsFactors = FALSE)
species_vals <- unique(df$Species)
date_vals <- unique(df$Sampling_date_order)
plot_vals <- unique(df$plot)
# Create the array with dimensions based on unique Species, Sampling_date_order, and plot
metacomm_tsdata <- array(0, dim = c(length(species_vals), length(date_vals), length(plot_vals)))
# Step 3: Populate the array with values from the data frame
for(i in 1:nrow(df)){
# Map Species, Sampling_date_order, and plot to their corresponding indices
species_index <- which(species_vals == df$Species[i])
date_index <- which(date_vals == df$Sampling_date_order[i])
plot_index <- which(plot_vals == df$plot[i])
# Assign the value from the data frame (Abundance) to the array
metacomm_tsdata[species_index, date_index, plot_index] <- df$Abundance[i]
}
test=var.partition(metacomm_tsdata)
test
prop_patches_result <- mark(df %>%
group_by(Species, plot) %>%
dplyr::summarise(mean_abundance = mean(Abundance)) %>%
filter(mean_abundance  > 0) %>%
dplyr::summarise(n_patches = n()) %>%
mutate(prop_patches = n_patches/max(df$plot)) %>%
summarise(mean_prop_patches = mean(prop_patches), min_prop_patches = min(prop_patches), max_prop_patches = max(prop_patches)),
iterations = 1000,
check = TRUE,
time_unit = "ms")
library(data.table)
library(tidyverse)
library(bench)
## R packages that provide equivalent functions of my package
library(adespatial)
library(DNCImper)
prop_patches_result <- mark(df %>%
group_by(Species, plot) %>%
dplyr::summarise(mean_abundance = mean(Abundance)) %>%
filter(mean_abundance  > 0) %>%
dplyr::summarise(n_patches = n()) %>%
mutate(prop_patches = n_patches/max(df$plot)) %>%
summarise(mean_prop_patches = mean(prop_patches), min_prop_patches = min(prop_patches), max_prop_patches = max(prop_patches)),
iterations = 1000,
check = TRUE,
time_unit = "ms")
prop_patches_result
execution_time_millisecond <- as.numeric(mean(prop_patches_result$time[[1]])) * 1000
memory_usage_mib <- as.numeric(prop_patches_result$mem_alloc) / 1.048576e+6
cat("Execution Time (Milliseconds):", execution_time_millisecond, "\n")
cat("Memory Usage (MiB):", memory_usage_mib, "\n")
CV_meta_simple_result <- mark(var.partition(metacomm_tsdata),
iterations = 1000,
check = TRUE,
time_unit = "ms")
var.partition <- function(metacomm_tsdata){
## The function "var.partition" performs the partitioning of variability
## across hierarchical levesl within a metacommunity.
## The input array "metacomm_tsdata" is an N*T*M array. The first dimension represents N species,
## the second represents time-series observations of length T, and the third represents M local communities.
## The output includes four variability and four synchrony metrics as defined in the main text.
## Note that, to be able to handle large metacommunities, this code has avoided calculating all covariance.
ts_metacom <- apply(metacomm_tsdata,2,sum)
ts_patch <- apply(metacomm_tsdata,c(2,3),sum)
ts_species <- apply(metacomm_tsdata,c(1,2),sum)
sd_metacom <- sd(ts_metacom)
sd_patch_k <- apply(ts_patch,2,sd)
sd_species_i <- apply(ts_species,1,sd)
sd_species_patch_ik <- apply(metacomm_tsdata,c(1,3),sd)
mean_metacom <- mean(ts_metacom)
CV_S_L <- sum(sd_species_patch_ik)/mean_metacom
CV_C_L <- sum(sd_patch_k)/mean_metacom
CV_S_R <- sum(sd_species_i)/mean_metacom
CV_C_R <- sd_metacom/mean_metacom
phi_S_L2R <- CV_S_R/CV_S_L
phi_C_L2R <- CV_C_R/CV_C_L
phi_S2C_L <- CV_C_L/CV_S_L
phi_S2C_R <- CV_C_R/CV_S_R
partition_3level <- c(CV_S_L=CV_S_L, CV_C_L=CV_C_L, CV_S_R=CV_S_R, CV_C_R=CV_C_R,
phi_S_L2R=phi_S_L2R, phi_C_L2R=phi_C_L2R, phi_S2C_L=phi_S2C_L,
phi_S2C_R=phi_S2C_R)
return(partition_3level)
}
var.partition(metacomm_tsdata)
CV_meta_simple_result <- mark(var.partition(metacomm_tsdata),
iterations = 1000,
check = TRUE,
time_unit = "ms")
execution_time_millisecond <- as.numeric(mean(CV_meta_simple_result$time[[1]])) * 1000
memory_usage_mib <- as.numeric(CV_meta_simple_result$mem_alloc) / 1.048576e+6
CV_meta_simple_result
cat("Execution Time (Milliseconds):", execution_time_millisecond, "\n")
cat("Memory Usage (MiB):", memory_usage_mib, "\n")
as.numeric(mean(CV_meta_simple_result$time[[1]]))
var.partition(metacomm_tsdata)
CV_simple_function <- function(species, time, plot, abundance){
# Extract unique values for Species, Sampling_date_order, and plot
species_vals <- unique(species)
date_vals <- unique(time)
plot_vals <- unique(plot)
# Create the array with dimensions based on unique Species, Sampling_date_order, and plot
metacomm_tsdata <- array(0, dim = c(length(species_vals), length(date_vals), length(plot_vals)))
# Populate the array with values from the data frame
for(i in 1:nrow(df)){
# Map Species, Sampling_date_order, and plot to their corresponding indices
species_index <- which(species_vals == species[i])
date_index <- which(date_vals == time[i])
plot_index <- which(plot_vals == plot[i])
# Assign the value from the data frame (Abundance) to the array
metacomm_tsdata[species_index, date_index, plot_index] <- abundance[i]
}
result <- var.partition(metacomm_tsdata)
return(result)
}
CV_simple_function(df$Species, df$Sampling_date_order, df$plot, df$Abundance)
CV_meta_simple_result <- mark(CV_simple_function(df$Species, df$Sampling_date_order, df$plot, df$Abundance),
iterations = 1000,
check = TRUE,
time_unit = "ms")
CV_meta_simple_result
CV_meta_simple_result <- mark(CV_simple_function(df$Species, df$Sampling_date_order, df$plot, df$Abundance),
iterations = 1000,
check = TRUE,
time_unit = "ms")
CV_meta_simple_result
execution_time_millisecond <- as.numeric(mean(CV_meta_simple_result$time[[1]])) * 1000
memory_usage_mib <- as.numeric(CV_meta_simple_result$mem_alloc) / 1.048576e+6
# Print the results
cat("Execution Time (Milliseconds):", execution_time_millisecond, "\n")
cat("Memory Usage (MiB):", memory_usage_mib, "\n")
comm_df_for_DNCI<-read.csv("~/.julia/dev/MetaCommunityMetrics/benchmarks/benchmark_r/data/DNCI_comm_t50.csv")
grouping_for_DNCI<-read.csv("~/.julia/dev/MetaCommunityMetrics/benchmarks/benchmark_r/data/cluster_list_t50.csv")
comm_df_for_DNCI
grouping_for_DNCI
groups <- grouping_for_DNCI$Group
DNCImper:::DNCI_multigroup(comm_df_for_DNCI,
groups, Nperm = 100,
symmetrize = FALSE,
plotSIMPER = FALSE)
DNCImper:::DNCI_multigroup(comm_df_for_DNCI,
groups, Nperm = 100,
symmetrize = FALSE,
plotSIMPER = FALSE)
DNCI_multigroup_result <- mark(DNCImper:::DNCI_multigroup(comm_df_for_DNCI,
groups, Nperm = 100,
symmetrize = FALSE,
plotSIMPER = FALSE),
iterations = 1000,
check = TRUE,
time_unit = "ms")
